{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIgM6C9HYUhm"
   },
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
    "\n",
    "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
    "\n",
    "Useful links:\n",
    "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
    "- [Norvig's dataset](https://norvig.com/big.txt)\n",
    "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
    "\n",
    "Grading:\n",
    "- 60 points - Implement spelling correction\n",
    "- 20 points - Justify your decisions\n",
    "- 20 points - Evaluate on a test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-vb8yFOGRDF"
   },
   "source": [
    "## Implement context-sensitive spelling correction\n",
    "\n",
    "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
    "\n",
    "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
    "\n",
    "You may also want to implement:\n",
    "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
    "- some recent (or not very recent) paper on this topic,\n",
    "- solution which takes into account keyboard layout and associated misspellings,\n",
    "- efficiency improvement to make the solution faster,\n",
    "- any other idea of yours to improve the Norvigâ€™s solution.\n",
    "\n",
    "IMPORTANT:  \n",
    "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
    "- Your implementation\n",
    "- Analysis of why the implemented approach is suggested\n",
    "- Improvements of the original approach that you have chosen to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:24:10.551537Z",
     "iopub.status.busy": "2024-03-22T18:24:10.550789Z",
     "iopub.status.idle": "2024-03-22T18:24:11.458604Z",
     "shell.execute_reply": "2024-03-22T18:24:11.457110Z",
     "shell.execute_reply.started": "2024-03-22T18:24:10.551537Z"
    },
    "id": "MoQeEsZvHvvi"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# implement Norvig\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "class Norvig:\n",
    "    def __init__(self, filename):\n",
    "        self.WORDS = Counter(words(open(filename).read()))\n",
    "        self.N = sum(self.WORDS.values())\n",
    "    \n",
    "    def P(self, word): \n",
    "        \"Probability of `word`.\"\n",
    "        return self.WORDS[word] / self.N\n",
    "    \n",
    "    def correction(self, word): \n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "    \n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or set([word]))\n",
    "    \n",
    "    def known(self, words): \n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.WORDS)\n",
    "    \n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "    \n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "\n",
    "norvig = Norvig('big.txt') #big.txt from norvig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:24:11.461291Z",
     "iopub.status.busy": "2024-03-22T18:24:11.461291Z",
     "iopub.status.idle": "2024-03-22T18:26:11.904505Z",
     "shell.execute_reply": "2024-03-22T18:26:11.903006Z",
     "shell.execute_reply.started": "2024-03-22T18:24:11.461291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c97e7266b44305a752d876173e1891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1020385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# implement bigram model:\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class Bigram:\n",
    "    def __init__(self, filename):\n",
    "        self.DICT = {}\n",
    "        self.N = 0\n",
    "        df = pd.read_csv(filename, sep='\\t', header=None, encoding='mbcs')\n",
    "        for _, row in tqdm(df.iterrows(), total = len(df)):\n",
    "            self.N += row[0]\n",
    "            self.DICT[(row[1], row[2])] = row[0]\n",
    "    \n",
    "    def P(self, word1, word2): \n",
    "        return self.DICT.get((word1, word2), 0) / self.N\n",
    "\n",
    "    def candidates1(self, word1):\n",
    "        return set(w2 for w1, w2 in self.DICT.keys() if w1 == word1)\n",
    "\n",
    "    def candidates2(self, word2):\n",
    "        return set(w1 for w1, w2 in self.DICT.keys() if w2 == word2)\n",
    "\n",
    "bigram = Bigram('bigrams.txt') #bigrams.txt from moodle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.907505Z",
     "iopub.status.busy": "2024-03-22T18:26:11.906006Z",
     "iopub.status.idle": "2024-03-22T18:26:11.931504Z",
     "shell.execute_reply": "2024-03-22T18:26:11.930005Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.907505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stay safe and pay taxes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def norm(x):\n",
    "    if x.sum() == 0:\n",
    "        return x\n",
    "    return x / x.sum()\n",
    "\n",
    "def correct(str, norvig=norvig, bigram=bigram): # use two models together\n",
    "    w = words(str)\n",
    "    n = len(w)\n",
    "    \n",
    "    corrections = [list(norvig.candidates(i)) for i in w] # possible corrections for every word according to norvig\n",
    "    norvig_prob = [np.array(list(map(norvig.P, i))) for i in corrections] # probabilities for corrections for every word according to norvig\n",
    "    norvig_prob = list(map(norm, norvig_prob)) # normalized\n",
    "\n",
    "    bigram_prob = [np.zeros(i.size) for i in norvig_prob] # set up probability array for bigram\n",
    "    bpv = np.vectorize(bigram.P) # make bigram.P numpy-compatible\n",
    "    \n",
    "    for i in range(n-1): # for every pair of words\n",
    "        a = np.array(corrections[i]) # for all their possible corrections\n",
    "        b = np.array(corrections[i+1])\n",
    "        mat = bpv(a[:, np.newaxis], b) # build a matrix of cross-probabilities\n",
    "        bigram_prob[i] += mat.sum(axis=1) # sum it by rows and columns and add to total bigram probabilities\n",
    "        bigram_prob[i+1] = mat.sum(axis=0) \n",
    "\n",
    "    bigram_prob = list(map(norm, bigram_prob)) # normalized\n",
    "\n",
    "    total_prob = [norvig_prob[i] * bigram_prob[i] for i in range(n)] # multiply probabilities \n",
    "    total_prob = list(map(norm, total_prob)) # normalized\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        if len(corrections[i]) == 0:\n",
    "            result.append(w[i])\n",
    "        else:\n",
    "            idx = total_prob[i].argmax()\n",
    "            result.append(corrections[i][idx])\n",
    "\n",
    "    if 0: #debug\n",
    "        print(corrections)\n",
    "        print(norvig_prob)\n",
    "        print(bigram_prob)\n",
    "            \n",
    "    return ' '.join(result)\n",
    "\n",
    "correct(\"sray safe anf pay taces\") #check if it actually works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oML-5sJwGRLE"
   },
   "source": [
    "## Justify your decisions\n",
    "\n",
    "Write down justificaitons for your implementation choices. For example, these choices could be:\n",
    "- Which ngram dataset to use\n",
    "- Which weights to assign for edit1, edit2 or absent words probabilities\n",
    "- Beam search parameters\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xb_twOmVsC6"
   },
   "source": [
    "My approach is to use Norvig's solution to pefrform baseline error correction, then apply N-gram model to select the most context appropriate correction.\n",
    "\n",
    "Norvig's solution on itself is a decent spelling correction algorithm, capable of fixing most spelling errors. The only problem which it has is lack of context-sensitivity - a strong side of N-gram models. By combining this two approaches, we could create a good context-sensitive spelling correction model.\n",
    "\n",
    "My implementation works by first building a list of possible corrections for each word using Norvig, then applying Bi-grams approach to calculate probabilities for each word pair, keeping running totals for each correction for each word. After that, it selects the most probable word for each position, buy multiplying Norvig scores by Bi-grams scores and picking the likeliest word.\n",
    "\n",
    "This is a simple and straightforward solution to combine Norvig approach with N-grams method.\n",
    "\n",
    "Bi-grams should be enough to guess the right correction for a word, since spelling correction is used most of the time on short phrases (like when googling), where the adjacent words is enough to infer the meaning of a word. Implementing tri-grams or more-grams could potentially improve the accuracy on larger sentences, but would make algorithm less usable on smaller sets and hinder performace severely.\n",
    "\n",
    "Possible improvemens: \n",
    "1. Use a better dataset (preferably the same one for Norvig part and Bigram part) # autocorrection datasets are hard to find\n",
    "2. Modify the norvig to produce weighted scores (based on if they are direct, 1-edit or 2-edit) # I tried, but it resulted in worse performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46rk65S4GRSe"
   },
   "source": [
    "## Evaluate on a test set\n",
    "\n",
    "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.933752Z",
     "iopub.status.busy": "2024-03-22T18:26:11.933005Z",
     "iopub.status.idle": "2024-03-22T18:26:11.945370Z",
     "shell.execute_reply": "2024-03-22T18:26:11.944629Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.933752Z"
    },
    "id": "OwZWaX9VVs7B"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say safe and pay faces'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "def norvig_wrapper(str, norvig=norvig): #baseline\n",
    "    return ' '.join(map(norvig.correction, words(str)))\n",
    "\n",
    "norvig_wrapper(\"sray safe anf pay taces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.947619Z",
     "iopub.status.busy": "2024-03-22T18:26:11.946869Z",
     "iopub.status.idle": "2024-03-22T18:26:11.956848Z",
     "shell.execute_reply": "2024-03-22T18:26:11.955357Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.947619Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def noize(text, p = 0.15):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    str = ''\n",
    "    for l in text:\n",
    "        if l in letters:\n",
    "            if random.random() < p:\n",
    "                str += random.choice(letters)\n",
    "            else:\n",
    "                str += l\n",
    "        else:\n",
    "            str += l\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.959850Z",
     "iopub.status.busy": "2024-03-22T18:26:11.958348Z",
     "iopub.status.idle": "2024-03-22T18:26:11.975819Z",
     "shell.execute_reply": "2024-03-22T18:26:11.974323Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.959850Z"
    }
   },
   "outputs": [],
   "source": [
    "# totally not stolen from random place in the internet\n",
    "walloftext = \"anarchism is political philosophy and movement that is sceptical of authority and rejects all involuntary coercive forms of hierarchy anarchism calls for the abolition of the state which it holds to be undesirable unnecessary and harmful it is usually described alongside libertarian marxism as the libertarian wing libertarian socialism of the socialist movement and as having historical association with anti capitalism and socialism the history of anarchism goes back to prehistory when humans arguably lived in anarchistic societies long before the establishment of formal states realms or empires with the rise of organised hierarchical bodies scepticism toward authority also rose but it was not until the th century that self conscious political movement emerged during the latter half of the th and the first decades of the th century the anarchist movement flourished in most parts of the world and had significant role in workers struggles for emancipation various anarchist schools of thought formed during this period anarchists have taken part in several revolutions most notably in the spanish civil war whose end marked the end of the classical era of anarchism in the last decades of the th and into the st century the anarchist movement has been resurgent once more anarchism employs diversity of tactics in order to meet its ideal ends which can be broadly separated into revolutionary and evolutionary tactics there is significant overlap between the two which are merely descriptive revolutionary tactics aim to bring down authority and state having taken violent turn in the past evolutionary tactics aim to prefigure what an anarchist society would be like anarchist thought criticism and praxis have played part in diverse areas of human society criticisms of anarchism include claims that it is internally inconsistent violent or utopian etymology terminology and definition wilhelm weitling an example of writer who added to anarchist theory without using the exact term the etymological origin of anarchism is from the ancient greek anarkhia meaning without ruler composed of the prefix an without and the word arkhos leader or ruler the suffix ism denotes the ideological current that favours anarchy anarchism appears in english from as anarchisme and anarchy from early english usages emphasised sense of disorder various factions within the french revolution labelled their opponents as anarchists although few such accused shared many views with later anarchists many revolutionaries of the th century such as william godwin and wilhelm weitling would contribute to the anarchist doctrines of the next generation but they did not use anarchist or anarchism in describing themselves or their beliefs the first political philosopher to call himself an anarchist was pierre joseph proudhon marking the formal birth of anarchism in the mid th century since the and beginning in france libertarianism has often been used as synonym for anarchism and its use as synonym\"\n",
    "target = np.array(words(walloftext))\n",
    "\n",
    "random.seed(42)\n",
    "wallofnoize = noize(walloftext, p = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.980319Z",
     "iopub.status.busy": "2024-03-22T18:26:11.979571Z",
     "iopub.status.idle": "2024-03-22T18:26:11.988789Z",
     "shell.execute_reply": "2024-03-22T18:26:11.987295Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.980319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do nothing: 0.48283261802575106\n"
     ]
    }
   ],
   "source": [
    "out = np.array(words(wallofnoize))\n",
    "score = np.mean(out == target)\n",
    "print(f\"Do nothing: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:11.994040Z",
     "iopub.status.busy": "2024-03-22T18:26:11.993291Z",
     "iopub.status.idle": "2024-03-22T18:26:28.617724Z",
     "shell.execute_reply": "2024-03-22T18:26:28.616995Z",
     "shell.execute_reply.started": "2024-03-22T18:26:11.994040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norvig: 0.7918454935622318\n"
     ]
    }
   ],
   "source": [
    "out = np.array(words(norvig_wrapper(wallofnoize)))\n",
    "score = np.mean(out == target)\n",
    "print(f\"Norvig: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T18:26:28.619976Z",
     "iopub.status.busy": "2024-03-22T18:26:28.619225Z",
     "iopub.status.idle": "2024-03-22T18:26:45.064887Z",
     "shell.execute_reply": "2024-03-22T18:26:45.063392Z",
     "shell.execute_reply.started": "2024-03-22T18:26:28.619976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram + Norvig: 0.7918454935622318\n"
     ]
    }
   ],
   "source": [
    "out = np.array(words(correct(wallofnoize)))\n",
    "score = np.mean(out == target)\n",
    "print(f\"Bigram + Norvig: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is somewhat underwhelming, but it is present. This could probably be fixed with a better dataset(s) but i couldn't find anything that is as usable as what is provided."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
